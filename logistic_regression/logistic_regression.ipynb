{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$y = \\sigma(wx + b)$$\n",
    "### Loss Function\n",
    "\n",
    "Use notation $y \\in \\{-1, 1\\}$. Then\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "P(y=1|x)  = \\sigma (f(x))  = \\frac{1}{1 + e^{-f(x)}} \\\\\n",
    "P(y=-1|x)  = 1 - \\sigma (f(x))  = \\frac{1}{1 + e^{f(x)}}\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "So in both cases:\n",
    "$$\n",
    "P(y_i | x_i) = \\frac{1}{1 + e^{- y_i f(x_i)}}\n",
    "$$\n",
    "\n",
    "Assuming independence, the likelihood is:\n",
    "$$\n",
    "\\prod_i^N{\\frac{1}{1+e^{-y_i f(x_i)}}}\n",
    "$$\n",
    "\n",
    "and the negative likelihood is:\n",
    "$$\n",
    "= \\sum_i^N{ \\log(1 + e^{-y_i f(x_i)})  }\n",
    "$$\n",
    "\n",
    "which defines the loss function.\n",
    "\n",
    "\n",
    "\n",
    "Binary Cross Entropy(Other cases): \n",
    "$$C(y, \\hat{y}) = -[\\hat{y} \\ln(y) + (1 - \\hat{y}) \\ln(1 - y)]$$\n",
    "\n",
    "Update:\n",
    "$$w_i \\leftarrow w_i - \\eta (y - \\hat{y}) x_i$$\n",
    "$$b \\leftarrow b - \\eta (y - \\hat{y})$$\n",
    "\n",
    "\n",
    "### Points\n",
    "+ Update weights only when prediction fails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orris/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../data/train_binary.csv', header=0)\n",
    "data = raw_data.values\n",
    "imgs = data[0:, 1:] # for one row, the first column is the label followed by the image data\n",
    "labels = data[:, 0]\n",
    "\n",
    "# normalize\n",
    "imgs = imgs / 255\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, random_state=23323)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self):\n",
    "        self.learning_rate = 1e-5\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x: 1D array\n",
    "        '''\n",
    "        return self._sigmoid((self.w * x).sum() + self.b)\n",
    "        \n",
    "    def fit(self, features, labels, max_iter=50000):\n",
    "        '''\n",
    "            features: (B, feature_size + 1)\n",
    "        '''\n",
    "        self.w = np.zeros(len(features[0]))\n",
    "        self.b = 0.0\n",
    "        count = 0\n",
    "\n",
    "        while count < max_iter:\n",
    "            n = random.randint(0, features.shape[0] - 1)\n",
    "\n",
    "            feature = features[n]\n",
    "            label = labels[n]\n",
    "            \n",
    "            y_pred = self.forward(feature)\n",
    "            if int(y_pred > 0.5) == label:\n",
    "                count += 1\n",
    "                continue # !!! Update only when prediction fails\n",
    "\n",
    "            self.w -= self.learning_rate * (y_pred - label) * feature\n",
    "            self.b -= self.learning_rate * (y_pred - label)\n",
    "            \n",
    "    def predict(self, features):\n",
    "        y_predicted = list()\n",
    "        for feature in features:\n",
    "            y_predicted.append(1 if self.forward(feature) > 0.5 else 0)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892496392496393\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_predicted = lr.predict(x_test)\n",
    "score = accuracy_score(y_predicted, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
