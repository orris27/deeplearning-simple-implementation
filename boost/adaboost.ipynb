{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHpDgl2PhL3K"
   },
   "source": [
    "# AdaBoost\n",
    "\n",
    "Input: Given training dataset: $T = {(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)}$, where $N$ is the size of training dataset, $y_i = \\{-1, +1\\}$.\n",
    "\n",
    "Ouput: A linear combination of classifiers $G(x) = \\alpha_1 G_1(x) + \\alpha_2 G_2(x) + \\ldots + \\alpha_m G_m(x)$, where $m$ is the number of classifiers.\n",
    "\n",
    "## AdaBoost Algorithm\n",
    "### 1. Train\n",
    "1. Initialize the weights for all samples:\n",
    "$$D_1 = (w_{1, 1}, w_{1, 2}, \\ldots, w_{1, N}), w_{1, i} = \\frac{1}{N}, i = 1, 2, \\ldots, N$$\n",
    "2. For each base learner G_k(x) do\n",
    "    1. Determine the base learner $G_k(x)$ based on some rules. For example, if the classifier uses threshold for classification, we can search all the possible thresholds and choose the one with least error score (the error score is calculated using the formula below)\n",
    "    2. Fit the weak classifier to the training set to compute the error for the base learner\n",
    "    $$ e_k = \\sum_{i=1}^N {{w_{k, i}}_{G_k(x_i) \\neq y_i }} $$\n",
    "    3. Calculate the weight for the current weak classifier\n",
    "    $$\\alpha_k = \\frac{1}{2} \\ln{\\frac{1 - e_k}{e_k}}$$\n",
    "    4. Update the weights for each point:\n",
    "    $$D_{k+1} = (w_{k+1, 1}, w_{k+1, 2}, \\ldots, w_{k+1, N})$$\n",
    "    $$w_{k+1, i} = \\frac{w_{k, i} e^{-\\alpha_k y_i G_k(x_i)}}{Z_k} $$\n",
    "    $$Z_k = \\sum_{i=1}^N{w_{k, i} e^{-\\alpha_k y_i G_k(x_i)}}$$\n",
    "    \n",
    "3. Combine the classifiers\n",
    "$$ G(x) = \\text{sign}( \\alpha_1 G_1(x) + \\alpha_2 G_2(x) + \\ldots + \\alpha_m G_m(x) )$$\n",
    "\n",
    "\n",
    "### 2. Predict\n",
    "$$ G(x) = \\text{sign}( \\alpha_1 G_1(x) + \\alpha_2 G_2(x) + \\ldots + \\alpha_m G_m(x) )$$\n",
    "\n",
    "## Theorem\n",
    "1. The summation of weights of samples equal to 1:\n",
    "$$\\sum_{i=1}^N{w_{k, i}} = 1, k=1,2, \\ldots, m$$\n",
    "2. The summation of weights of classifiers might not be 1:\n",
    "$$\\sum_{k=1}^m{\\alpha_k} \\neq 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgG0MsmOhPul"
   },
   "source": [
    "## Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B45FSwOShRYv"
   },
   "source": [
    "### 1. Examples in LiHange Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SExQyXuneerW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def get_d(d, gm_x, y, alpha):\n",
    "    '''\n",
    "        d: (N,), (w_1, w_2, ..., w_N)\n",
    "        alpha: scalar\n",
    "        y: (N, ), true labels\n",
    "        gm_x: (N, ), predicted labels\n",
    "    '''\n",
    "    z = np.sum(d * np.exp(-alpha * y * gm_x))\n",
    "    new_d = d / z * np.exp(-alpha * y * gm_x)\n",
    "    return new_d\n",
    "def get_alpha(e):\n",
    "    '''\n",
    "        e: scalar\n",
    "    '''\n",
    "    alpha = (1.0 / 2) * math.log((1 - e) / e) # 1 / 2 is int type\n",
    "    return alpha\n",
    "\n",
    "def update_d(d, gm_x, y):\n",
    "    '''\n",
    "        d: weight of samples. (w_1, w_2, ..., w_N), (N,)\n",
    "        y: true labels. (N,)\n",
    "        gm_x: predicted labels (N,)\n",
    "    '''\n",
    "    e = np.sum(d[y != gm_x])\n",
    "    alpha = get_alpha(e)\n",
    "    return get_d(d, y, gm_x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BskJ2h-9hUib",
    "outputId": "da9a2b2b-4bbe-4044-d585-179fad474e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.16666667 0.16666667 0.16666667 0.07142857]\n"
     ]
    }
   ],
   "source": [
    "d1 = np.array([0.1] * 10)\n",
    "y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])\n",
    "g1_x = np.array([1] * 3 + [-1] * 7)\n",
    "\n",
    "d2 = update_d(d1, g1_x, y)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "u4NxbmVJhWMT",
    "outputId": "b48e3c66-af45-45b9-98b9-8caf8676b29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04545455 0.04545455 0.04545455 0.16666667 0.16666667 0.16666667\n",
      " 0.10606061 0.10606061 0.10606061 0.04545455]\n"
     ]
    }
   ],
   "source": [
    "g2_x = np.array([1] * 9 + [-1])\n",
    "\n",
    "d3 = update_d(d2, g2_x, y)\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "58igG6FIgwuA",
    "outputId": "c0b33e0a-84cc-4e03-8dc2-a5499b74d26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125      0.125      0.125      0.10185185 0.10185185 0.10185185\n",
      " 0.06481481 0.06481481 0.06481481 0.125     ]\n"
     ]
    }
   ],
   "source": [
    "g3_x = np.array([1] * 6 + [-1] * 4)\n",
    "\n",
    "d4 = update_d(d3, g3_x, y)\n",
    "print(d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nBGusrii6s6"
   },
   "source": [
    "### 2. MNIST\n",
    "reference:[lihang_book_algorithm](https://github.com/WenDesi/lihang_book_algorithm/blob/master/AdaBoost/adaboost.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSSeag4QjARr"
   },
   "source": [
    "#### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qI20Liepi9xy"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8xVgVKfjGBg"
   },
   "source": [
    "#### 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GRP56RXjQVu"
   },
   "outputs": [],
   "source": [
    "def binarization(img):\n",
    "    bin_img = img.astype(np.uint8)\n",
    "    cv2.threshold(bin_img, 50, 1, cv2.THRESH_BINARY_INV, bin_img) # pixel = 0 if value > 50 else 1\n",
    "    return bin_img\n",
    "\n",
    "raw_data = pd.read_csv('/content/gdrive/My Drive/data/train_binary.csv', header=0) # binary classification\n",
    "data = raw_data.values\n",
    "imgs = data[0:, 1:] # for one row, the first column is the label followed by the image data\n",
    "labels = data[:, 0]\n",
    "\n",
    "# reduce the size of training dataset to train faster\n",
    "imgs = imgs[:1000] # (1000, 784)\n",
    "labels = labels[:1000] # (1000,)\n",
    "\n",
    "# binarization\n",
    "for index, img in enumerate(imgs):\n",
    "    imgs[index] = binarization(img)\n",
    "\n",
    "# map 0 to -1 for labels\n",
    "labels = np.array(list(map(lambda x:int(2*x - 1), labels)))\n",
    "    \n",
    "# choose 33% of samples for training, and the rest for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels, test_size=0.33, random_state=23323)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEiBp-RHjJfb"
   },
   "source": [
    "#### 3. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvKJSROzjekU"
   },
   "outputs": [],
   "source": [
    "class BaseClassifier(object): # +1 if x > threshold else -1\n",
    "    def fit(self, features, labels, d):\n",
    "        '''\n",
    "            features: (B, )\n",
    "            labels: (B, ), {-1, +1}\n",
    "            d: (w1, w2, ..., wN)\n",
    "        '''\n",
    "        # select the best sign and threshold\n",
    "        best_error = math.inf\n",
    "        for sign in [\"<\", \">\"]:\n",
    "            for threshold in [-0.5, 0.5, 1.5]:\n",
    "                self.sign = sign\n",
    "                self.threshold = threshold\n",
    "                y_predicted = self.predict(features)\n",
    "                error = np.sum(d[y_predicted != labels])\n",
    "                if error < best_error: # store current model\n",
    "                    best_error = error\n",
    "                    best_sign = sign\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "        self.sign = best_sign\n",
    "        self.threshold = best_threshold\n",
    "        return best_error      \n",
    "      \n",
    "    def predict(self, features):\n",
    "        '''\n",
    "            features: (B,)\n",
    "        '''\n",
    "        y_predicted = list()\n",
    "        for feature in features:\n",
    "            if (self.sign == '<' and feature < self.threshold) or (self.sign == '>' and feature > self.threshold):\n",
    "                y_predicted.append(1)\n",
    "            else:\n",
    "                y_predicted.append(-1)\n",
    "        return np.array(y_predicted)\n",
    "    def __str__(self):\n",
    "        return '1 if x {} {} else 0'.format(self.sign, self.threshold)\n",
    "              \n",
    "class AdaBoost(object):\n",
    "    def __init__(self, m=20):\n",
    "        self.m = m # number of base classifiers\n",
    "\n",
    "    def _get_alpha(self, e):\n",
    "        '''\n",
    "            e: scalar\n",
    "        '''\n",
    "        alpha = (1.0 / 2) * math.log((1 - e) / e) # 1 / 2 is int type\n",
    "        return alpha\n",
    "      \n",
    "      \n",
    "    def _get_d(self, d, gm_x, y, alpha):\n",
    "        '''\n",
    "            d: (N,), (w_1, w_2, ..., w_N)\n",
    "            alpha: scalar\n",
    "            y: (N, ), true labels\n",
    "            gm_x: (N, ), predicted labels\n",
    "        '''\n",
    "        z = np.sum(d * np.exp(-alpha * y * gm_x))\n",
    "        new_d = d / z * np.exp(-alpha * y * gm_x)\n",
    "        return new_d\n",
    "          \n",
    "      \n",
    "    def fit(self, features, labels):\n",
    "        '''\n",
    "            features: (B, feature_size)\n",
    "        '''\n",
    "        self.alphas = list()\n",
    "        self.i_classifiers = list() # one classifier is determined by index of feature and corresponding feature\n",
    "        \n",
    "        \n",
    "        print('N:', features.shape[0])\n",
    "        d = np.array([1 / features.shape[0]] * features.shape[0])\n",
    "        \n",
    "        # iterate m classifiers\n",
    "        for i in range(self.m):\n",
    "            error, index, classifier = self._find_classifier(features, labels, d) # (index of feature, Sign classifier)\n",
    "            \n",
    "            print('k={} || error:{}'.format(i, error))\n",
    "            print('k={} || classifier:{}'.format(i, classifier))\n",
    "            print('k={} || index:{}'.format(i, index))\n",
    "            \n",
    "            # calculate weight of current classifier (alpha)\n",
    "            alpha = self._get_alpha(error)\n",
    "            print('k={} || alpha:{}'.format(i, alpha))\n",
    "            \n",
    "            # update weights of samples (d)\n",
    "            d = self._get_d(d, classifier.predict(features[:, index]), labels, alpha)\n",
    "            \n",
    "            self.alphas.append(alpha)\n",
    "            self.i_classifiers.append((index, classifier))\n",
    "            \n",
    "        self.alphas = np.array(self.alphas)\n",
    "        self.i_classifiers = np.array(self.i_classifiers)\n",
    "            \n",
    "    def predict(self, features):\n",
    "        y_predicted = np.zeros(features.shape[0])\n",
    "        for i in range(self.m):\n",
    "            alpha  = self.alphas[i]\n",
    "            (index, classifier) = self.i_classifiers[i]\n",
    "            y_predicted += alpha * classifier.predict(features[:, index])\n",
    "        return np.sign(y_predicted)\n",
    "      \n",
    "      \n",
    "    def _find_classifier(self, features, labels, d):\n",
    "        best_error = math.inf\n",
    "        for index in range(features.shape[1]):\n",
    "            classifier = BaseClassifier()\n",
    "            error = classifier.fit(features[:, index], labels, d)\n",
    "            if error < best_error:\n",
    "                best_error = error\n",
    "                best_classifier = classifier\n",
    "                best_index = index\n",
    "        return best_error, best_index, best_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07tpH3gfjLaS"
   },
   "source": [
    "#### 4. Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1508
    },
    "colab_type": "code",
    "id": "OtX3RzwcjJJU",
    "outputId": "7815c1c0-194e-4bbd-9d87-385ffdb23c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 670\n",
      "k=0 || error:0.08656716417910448\n",
      "k=0 || classifier:1 if x > 0.5 else 0\n",
      "k=0 || index:359\n",
      "k=0 || alpha:1.1781446359829533\n",
      "k=1 || error:0.14550935316655395\n",
      "k=1 || classifier:1 if x < 0.5 else 0\n",
      "k=1 || index:435\n",
      "k=1 || alpha:0.885132594620742\n",
      "k=2 || error:0.18600766381303824\n",
      "k=2 || classifier:1 if x > 0.5 else 0\n",
      "k=2 || index:441\n",
      "k=2 || alpha:0.7380815373971066\n",
      "k=3 || error:0.253161490551473\n",
      "k=3 || classifier:1 if x > 0.5 else 0\n",
      "k=3 || index:511\n",
      "k=3 || alpha:0.5409106943050461\n",
      "k=4 || error:0.2891682607321551\n",
      "k=4 || classifier:1 if x < 1.5 else 0\n",
      "k=4 || index:0\n",
      "k=4 || alpha:0.4497135062042572\n",
      "k=5 || error:0.20771102822392118\n",
      "k=5 || classifier:1 if x < 0.5 else 0\n",
      "k=5 || index:380\n",
      "k=5 || alpha:0.6693891811298859\n",
      "k=6 || error:0.2881779709044539\n",
      "k=6 || classifier:1 if x > 0.5 else 0\n",
      "k=6 || index:656\n",
      "k=6 || alpha:0.45212483861074665\n",
      "k=7 || error:0.2579865586070224\n",
      "k=7 || classifier:1 if x > 0.5 else 0\n",
      "k=7 || index:397\n",
      "k=7 || alpha:0.528229936473063\n",
      "k=8 || error:0.25066544882409225\n",
      "k=8 || classifier:1 if x < 0.5 else 0\n",
      "k=8 || index:350\n",
      "k=8 || alpha:0.5475331853617506\n",
      "k=9 || error:0.2993225296988267\n",
      "k=9 || classifier:1 if x > 0.5 else 0\n",
      "k=9 || index:128\n",
      "k=9 || alpha:0.42526299753304475\n",
      "k=10 || error:0.29898711987347826\n",
      "k=10 || classifier:1 if x > 0.5 else 0\n",
      "k=10 || index:456\n",
      "k=10 || alpha:0.4260628828407289\n",
      "k=11 || error:0.29068430559345\n",
      "k=11 || classifier:1 if x > 0.5 else 0\n",
      "k=11 || index:416\n",
      "k=11 || alpha:0.4460314383976983\n",
      "k=12 || error:0.2595037328014331\n",
      "k=12 || classifier:1 if x < 0.5 else 0\n",
      "k=12 || index:490\n",
      "k=12 || alpha:0.5242747528405819\n",
      "k=13 || error:0.31513823818074793\n",
      "k=13 || classifier:1 if x > 0.5 else 0\n",
      "k=13 || index:275\n",
      "k=13 || alpha:0.38810280820360715\n",
      "k=14 || error:0.29481919608430296\n",
      "k=14 || classifier:1 if x > 0.5 else 0\n",
      "k=14 || index:656\n",
      "k=14 || alpha:0.4360459777867033\n",
      "k=15 || error:0.30297593863590205\n",
      "k=15 || classifier:1 if x > 0.5 else 0\n",
      "k=15 || index:570\n",
      "k=15 || alpha:0.4165832697884365\n",
      "k=16 || error:0.32464132163318005\n",
      "k=16 || classifier:1 if x > 0.5 else 0\n",
      "k=16 || index:238\n",
      "k=16 || alpha:0.36626148897927197\n",
      "k=17 || error:0.3265448564202478\n",
      "k=17 || classifier:1 if x > 0.5 else 0\n",
      "k=17 || index:651\n",
      "k=17 || alpha:0.3619270333626382\n",
      "k=18 || error:0.281784991174274\n",
      "k=18 || classifier:1 if x < 0.5 else 0\n",
      "k=18 || index:408\n",
      "k=18 || alpha:0.4678123209615123\n",
      "k=19 || error:0.3172563915704091\n",
      "k=19 || classifier:1 if x > 0.5 else 0\n",
      "k=19 || index:358\n",
      "k=19 || alpha:0.3832045728075992\n",
      "0.9818181818181818\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoost()\n",
    "ab.fit(x_train, y_train)\n",
    "y_predicted = ab.predict(x_test)\n",
    "score = accuracy_score(y_predicted, y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adaboost.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
