{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN on MNIST using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Usage: python dcgan-mnist.py\n",
    "    编写代码时的收获: 1. 计算梯度的的时候,使用各自的GradientTape\n",
    "                      2. 应用梯度的时候,使用各自的Optimizer\n",
    "                      3. 生成图像检查的时候,注意Discriminator传入的real_images和fake_images形状是一样的,根据这一点,我们可以将fake_images还原成可以看的图片\n",
    "                      4. Evaluate和Train的时候,Dropout和BatchNormal表现不一样,必须通过training控制\n",
    "                      5. eager mode还是什么原因,总之MNIST输入必须使用tf.keras.datasets.mnist.load_data()这个API,得到的结果是ndarray,形状为[60000, 28, 28] 和 [60000,]\n",
    "                      6. 真实图片可以考虑手动切换到[-1, 1]的区域之间,之后再传入网络\n",
    "                      7. Discriminator中如果报错最后全连接层时说shape不对,是因为real_images和fake_images的shape不对,前者已经定义好Fully_connected层的结构了,所以如果fake_images不正确就会出现问题\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.enable_eager_execution(config=config)\n",
    "# eager mode\n",
    "\n",
    "############################################################\n",
    "# Constants\n",
    "############################################################\n",
    "# noise_size\n",
    "noise_size = 100\n",
    "# num_epochs\n",
    "num_epochs = 300\n",
    "# batch_size\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Models\n",
    "############################################################\n",
    "# define generator: [batch_size, noise_size] => [batch_size, width, height, 1]\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # fc1\n",
    "        #self.dense1 = tf.keras.layers.Dense(width * height * 64, activation=None)\n",
    "        self.dense1 = tf.keras.layers.Dense(7* 7* 64, use_bias=False)\n",
    "        # bn1\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        # conv1\n",
    "        #self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=[5, 5], padding='same', activation=None)\n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=[5, 5], strides=[1, 1], padding='same', use_bias=False)\n",
    "        # bn2\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        # conv2\n",
    "        #self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=[5, 5], padding='same', activation=None)\n",
    "        self.conv2 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=[5, 5], strides=[2, 2], padding='same', use_bias=False)\n",
    "        # bn3\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        # conv3\n",
    "        #self.conv3 = tf.keras.layers.Conv2D(filters=1, kernel_size=[5, 5], padding='same', activation=None)\n",
    "        self.conv3 = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=[5, 5], strides=[2, 2], padding='same', use_bias=False)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # fc: [batch_size, noise_size] => [batch_size, 7 * 7 * 64]\n",
    "        net = self.dense1(inputs) \n",
    "        # BN\n",
    "        net = self.bn1(net, training=training)\n",
    "        # relu\n",
    "        net = tf.nn.relu(net)\n",
    "        # reshape: [batch_size, 7 * 7 * 64] => [batch_size, 7, 7, 64]\n",
    "        net = tf.reshape(net, [batch_size, 7, 7, 64]) \n",
    "        # Conv2DTranspose: [batch_size, 7, 7, 64] => [batch_size, 7, 7, 64]\n",
    "        net = self.conv1(net)\n",
    "        # BN\n",
    "        net = self.bn2(net, training=training)\n",
    "        # relu\n",
    "        net = tf.nn.relu(net)\n",
    "        # Conv2DTranspose: [batch_size, 7, 7, 64] => [batch_size, 7, 7, 32]\n",
    "        net = self.conv2(net)\n",
    "        # BN\n",
    "        net = self.bn3(net, training=training)\n",
    "        # relu\n",
    "        net = tf.nn.relu(net)\n",
    "        # Conv2DTranspose: [batch_size, 7, 7, 32] => [batch_size, 7, 7, 1]\n",
    "        net = self.conv3(net)\n",
    "        # tanh\n",
    "        net = tf.tanh(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "\n",
    "# define discriminator: [batch_size, n, n, 1] => [batch_size, 1]\n",
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # conv1\n",
    "        #self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=[5, 5], padding='same', activation=None)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=[5, 5], strides=[2, 2], padding='same')\n",
    "        # dropout: 0.3\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        # conv2\n",
    "        #self.conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=[5, 5], padding='same', activation=None)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=128, kernel_size=[5, 5], strides=[2, 2], padding='same')\n",
    "        # flatten\n",
    "        self.flatten1 = tf.keras.layers.Flatten()\n",
    "        # fc1\n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # Conv2D: [batch_size, n, n, 1] => [batch_size, n, n, 64]\n",
    "        net = self.conv1(inputs)\n",
    "        # leaky relu\n",
    "        net = tf.nn.leaky_relu(net)\n",
    "        # dropout:\n",
    "        net = self.dropout(net, training=training)\n",
    "        # Conv2D: [batch_size, n, n, 64] => [batch_size, n, n, 128]\n",
    "        net = self.conv2(net)\n",
    "        # leaky relu\n",
    "        net = tf.nn.leaky_relu(net)\n",
    "        # dropout\n",
    "        net = self.dropout(net, training=training)\n",
    "        # flatten\n",
    "        net = self.flatten1(net)\n",
    "        # FC: [batch_size, n, n, 128] => [batch_size, 1]\n",
    "        net = self.fc1(net)\n",
    "        return net\n",
    "\n",
    "\n",
    "# define discriminator loss: real_pred, fake_pred\n",
    "def get_disc_loss(real_pred, fake_pred):\n",
    "    # calc cross entropy of ones and real_pred\n",
    "    real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(real_pred), logits=real_pred)\n",
    "    # calc cross entropy of zeros and fake_pred\n",
    "    fake_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.zeros_like(fake_pred), logits=fake_pred)\n",
    "    # sum up\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "# define generator loss: fake_pred\n",
    "def get_gen_loss(fake_pred):\n",
    "    # calc cross entropy of ones and fake_pred\n",
    "    fake_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(fake_pred), logits=fake_pred)\n",
    "    # return\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "# We are normalizing the images to the range of [-1, 1]\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "buffer_size = 60000\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# new\n",
    "generator.call = tf.contrib.eager.defun(generator.call)\n",
    "discriminator.call = tf.contrib.eager.defun(discriminator.call)\n",
    "\n",
    "noise = np.random.uniform([batch_size, noise_size])\n",
    "# define a function that generates & saves a picture \n",
    "def generate_save_image(noise, epoch):\n",
    "    # get noise\n",
    "    # generate\n",
    "    fake_images = generator(noise, training=False)\n",
    "\n",
    "    # plt.figure\n",
    "    #plt.figure()\n",
    "    plt.figure(figsize=[4, 4])\n",
    "    # plt.imshow\n",
    "    #plt.imshow(fake_images[0].numpy())\n",
    "    image = np.squeeze(fake_images[0].numpy())\n",
    "    image = image * 127.5 + 127.5\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    # plt.savefig\n",
    "    plt.savefig(\"myimages/pic\" + str(epoch) + \".png\")\n",
    "\n",
    "#! Use different optimizer\n",
    "#opt = tf.train.AdamOptimizer()\n",
    "gen_opt = tf.train.AdamOptimizer(1e-4)\n",
    "disc_opt = tf.train.AdamOptimizer(1e-4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "# Train\n",
    "############################################################\n",
    "for epoch in range(num_epochs):\n",
    "    # get images, labels\n",
    "    for images in train_dataset:\n",
    "        # get noise \n",
    "        noise = tf.random_uniform([batch_size, noise_size])\n",
    "        # tape gradients\n",
    "        with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "            # generate a sample from noise\n",
    "            #fake_images = generator(noise)\n",
    "            fake_images = generator(noise, training=True)\n",
    "            # discriminate images\n",
    "            #real_pred = discriminator(images)\n",
    "            real_pred = discriminator(images, training=True)\n",
    "            # discriminate fake_images\n",
    "            #fake_pred = discriminator(fake_images)\n",
    "            fake_pred = discriminator(fake_images, training=True)\n",
    "\n",
    "            disc_loss = get_disc_loss(real_pred, fake_pred)\n",
    "            gen_loss = get_gen_loss(fake_pred)\n",
    "\n",
    "\n",
    "\n",
    "        # calc gradients for discriminator\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, discriminator.variables)\n",
    "        # calc gradients for generator\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, generator.variables)\n",
    "\n",
    "\n",
    "        # apply gradients to discriminator\n",
    "        disc_opt.apply_gradients(zip(disc_gradients, discriminator.variables))\n",
    "        # apply gradients to generator\n",
    "        gen_opt.apply_gradients(zip(gen_gradients, generator.variables))\n",
    "        #? How to train the model in the eager?\n",
    "\n",
    "        # generates & saves a picture\n",
    "        #generate_save_image(tf.random_normal([1, noise_size]), epoch)\n",
    "        generate_save_image(noise, epoch)\n",
    "\n",
    "\n",
    "        print(\"epoch={2}    gen_loss={0}    disc_loss={1}\".format(gen_loss, disc_loss, epoch))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
