{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Pytorch: [BatchNorm2d](https://pytorch.org/docs/master/nn.html#torch.nn.BatchNorm1d)\n",
    "\n",
    "Normalize each dimension(such as `x[:, k, :, :]` in CHW version):\n",
    "$$\\hat{x}^{(k)} = \\frac{x^{(k)} - \\textbf{E}[x^{(k)}]}{\\sqrt{  \\text{Var}[x^{(k)}] + \\epsilon   }}$$\n",
    "\n",
    "Scale and shift the normalized value:\n",
    "$$ y^{(k)} = \\gamma ^ {(k)} \\hat{x} ^{(k)} + \\beta^{(k)} $$\n",
    "\n",
    "For pytorch, $\\gamma$ and $\\beta$ are stored in `bn.weight` and `bn.bias` respectively. If `affine` is `False`, `bn` has no learnable parameters and thus `bn.weight` and `bn.bias` are `None`.\n",
    "\n",
    "```\n",
    "running_mean = (1 - momentum) * running_mean + momentum * batch_mean\n",
    "running_var  = (1 - momentum) * running_var  + momentum * batch_var\n",
    "```\n",
    "\n",
    "Note that `torch.var` is default to unbiased, which means that it is  $Var[x] = \\frac{m}{m - 1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn.eps: 1e-05\n",
      "y:\n",
      "tensor([[[[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]]]])\n",
      "y_mine:\n",
      "tensor([[[[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]],\n",
      "\n",
      "         [[-1.1963, -1.1138],\n",
      "          [-1.0313, -0.9488],\n",
      "          [-0.8663, -0.7838]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]],\n",
      "\n",
      "         [[ 0.7838,  0.8663],\n",
      "          [ 0.9488,  1.0313],\n",
      "          [ 1.1138,  1.1963]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = torch.arange(48).reshape(2, 4, 3, 2).float()\n",
    "bn = torch.nn.BatchNorm2d(4, affine=False)\n",
    "print('bn.eps:', bn.eps)\n",
    "y = bn(x)\n",
    "\n",
    "y_mine = torch.zeros_like(y)\n",
    "for i in range(4):\n",
    "    y_mine[:, i, :, :] = (x[:, i, :, :] - torch.mean(x[:, i, :, :])) / torch.sqrt(torch.var(x[:, i, :, :], unbiased=False) + bn.eps)\n",
    "\n",
    "print('y:', y, sep='\\n')\n",
    "print('y_mine:', y_mine, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn.bias: tensor([5., 5., 5., 5.])\n",
      "y:\n",
      "tensor([[[[4.7718, 4.7875],\n",
      "          [4.8033, 4.8190],\n",
      "          [4.8347, 4.8505]],\n",
      "\n",
      "         [[4.8400, 4.8511],\n",
      "          [4.8621, 4.8731],\n",
      "          [4.8842, 4.8952]],\n",
      "\n",
      "         [[4.7793, 4.7946],\n",
      "          [4.8098, 4.8250],\n",
      "          [4.8402, 4.8554]],\n",
      "\n",
      "         [[3.8254, 3.9064],\n",
      "          [3.9874, 4.0684],\n",
      "          [4.1494, 4.2304]]],\n",
      "\n",
      "\n",
      "        [[[5.1495, 5.1653],\n",
      "          [5.1810, 5.1967],\n",
      "          [5.2125, 5.2282]],\n",
      "\n",
      "         [[5.1048, 5.1158],\n",
      "          [5.1269, 5.1379],\n",
      "          [5.1489, 5.1600]],\n",
      "\n",
      "         [[5.1446, 5.1598],\n",
      "          [5.1750, 5.1902],\n",
      "          [5.2054, 5.2207]],\n",
      "\n",
      "         [[5.7696, 5.8506],\n",
      "          [5.9316, 6.0126],\n",
      "          [6.0936, 6.1746]]]], grad_fn=<ThnnBatchNormBackward>)\n",
      "y_mine:\n",
      "tensor([[[[4.7718, 4.7875],\n",
      "          [4.8033, 4.8190],\n",
      "          [4.8347, 4.8505]],\n",
      "\n",
      "         [[4.8400, 4.8511],\n",
      "          [4.8621, 4.8731],\n",
      "          [4.8842, 4.8952]],\n",
      "\n",
      "         [[4.7793, 4.7946],\n",
      "          [4.8098, 4.8250],\n",
      "          [4.8402, 4.8554]],\n",
      "\n",
      "         [[3.8254, 3.9064],\n",
      "          [3.9874, 4.0684],\n",
      "          [4.1494, 4.2304]]],\n",
      "\n",
      "\n",
      "        [[[5.1495, 5.1653],\n",
      "          [5.1810, 5.1967],\n",
      "          [5.2125, 5.2282]],\n",
      "\n",
      "         [[5.1048, 5.1158],\n",
      "          [5.1269, 5.1379],\n",
      "          [5.1489, 5.1600]],\n",
      "\n",
      "         [[5.1446, 5.1598],\n",
      "          [5.1750, 5.1902],\n",
      "          [5.2054, 5.2207]],\n",
      "\n",
      "         [[5.7696, 5.8506],\n",
      "          [5.9316, 6.0126],\n",
      "          [6.0936, 6.1746]]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bn = torch.nn.BatchNorm2d(4) # eps=1e-5, affine=True(gamma and beta are enabled)\n",
    "bn.bias[:] += 5 # set to 5\n",
    "print('bn.bias:', bn.bias.data)\n",
    "y = bn(x)\n",
    "\n",
    "\n",
    "y_mine = torch.zeros_like(y)\n",
    "for i in range(4):\n",
    "    y_mine[:, i, :, :] = (x[:, i, :, :] - torch.mean(x[:, i, :, :])) / torch.sqrt(torch.var(x[:, i, :, :], unbiased=False) + bn.eps) * bn.weight[i] + bn.bias[i]\n",
    "\n",
    "print('y:', y, sep='\\n')\n",
    "print('y_mine:', y_mine, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "$$y^{(k)} = \\frac{x^{(k)} - \\text{running_mean}^{(k)}}{\\sqrt{  \\text{running_var}^{(k)} + \\epsilon   }} * \\gamma^{(k)} + \\beta^{(k)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\n",
      "tensor([[[[ 0.0000,  0.0891],\n",
      "          [ 0.1781,  0.2672],\n",
      "          [ 0.3562,  0.4453]],\n",
      "\n",
      "         [[ 3.7017,  4.3187],\n",
      "          [ 4.9356,  5.5526],\n",
      "          [ 6.1695,  6.7865]],\n",
      "\n",
      "         [[ 9.0030,  9.7533],\n",
      "          [10.5035, 11.2538],\n",
      "          [12.0040, 12.7543]],\n",
      "\n",
      "         [[15.5209, 16.3832],\n",
      "          [17.2455, 18.1078],\n",
      "          [18.9700, 19.8323]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1375,  2.2266],\n",
      "          [ 2.3156,  2.4047],\n",
      "          [ 2.4937,  2.5828]],\n",
      "\n",
      "         [[18.5086, 19.1256],\n",
      "          [19.7425, 20.3595],\n",
      "          [20.9764, 21.5934]],\n",
      "\n",
      "         [[27.0091, 27.7593],\n",
      "          [28.5096, 29.2598],\n",
      "          [30.0101, 30.7603]],\n",
      "\n",
      "         [[36.2155, 37.0778],\n",
      "          [37.9401, 38.8023],\n",
      "          [39.6646, 40.5269]]]], grad_fn=<ThnnBatchNormBackward>)\n",
      "y_mine:\n",
      "tensor([[[[ 0.0000,  0.0891],\n",
      "          [ 0.1781,  0.2672],\n",
      "          [ 0.3562,  0.4453]],\n",
      "\n",
      "         [[ 3.7017,  4.3187],\n",
      "          [ 4.9356,  5.5526],\n",
      "          [ 6.1695,  6.7865]],\n",
      "\n",
      "         [[ 9.0030,  9.7533],\n",
      "          [10.5035, 11.2538],\n",
      "          [12.0040, 12.7543]],\n",
      "\n",
      "         [[15.5209, 16.3832],\n",
      "          [17.2455, 18.1078],\n",
      "          [18.9700, 19.8323]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1375,  2.2266],\n",
      "          [ 2.3156,  2.4047],\n",
      "          [ 2.4937,  2.5828]],\n",
      "\n",
      "         [[18.5086, 19.1256],\n",
      "          [19.7425, 20.3595],\n",
      "          [20.9764, 21.5934]],\n",
      "\n",
      "         [[27.0091, 27.7593],\n",
      "          [28.5096, 29.2598],\n",
      "          [30.0101, 30.7603]],\n",
      "\n",
      "         [[36.2155, 37.0778],\n",
      "          [37.9401, 38.8023],\n",
      "          [39.6646, 40.5269]]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bn = torch.nn.BatchNorm2d(4).eval() # eps=1e-5, affine=True(gamma and beta are enabled)\n",
    "y = bn(x)\n",
    "\n",
    "y_mine = torch.zeros_like(y)\n",
    "for i in range(4):\n",
    "    y_mine[:, i, :, :] = (x[:, i, :, :] - bn.running_mean[i]) / torch.sqrt(bn.running_var[i] + bn.eps) * bn.weight[i] + bn.bias[i]\n",
    "    \n",
    "print('y:', y, sep='\\n')\n",
    "print('y_mine:', y_mine, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4500, 2.0500, 2.6500, 3.2500])\n",
      "y:\n",
      "tensor([[[[-0.0314, -0.0097],\n",
      "          [ 0.0119,  0.0336],\n",
      "          [ 0.0552,  0.0768]],\n",
      "\n",
      "         [[ 0.5923,  0.7423],\n",
      "          [ 0.8922,  1.0422],\n",
      "          [ 1.1921,  1.3421]],\n",
      "\n",
      "         [[ 1.7050,  1.8874],\n",
      "          [ 2.0697,  2.2521],\n",
      "          [ 2.4344,  2.6168]],\n",
      "\n",
      "         [[ 3.0913,  3.3009],\n",
      "          [ 3.5105,  3.7201],\n",
      "          [ 3.9297,  4.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4881,  0.5098],\n",
      "          [ 0.5314,  0.5531],\n",
      "          [ 0.5747,  0.5964]],\n",
      "\n",
      "         [[ 4.1912,  4.3412],\n",
      "          [ 4.4912,  4.6411],\n",
      "          [ 4.7911,  4.9410]],\n",
      "\n",
      "         [[ 6.0815,  6.2639],\n",
      "          [ 6.4462,  6.6286],\n",
      "          [ 6.8109,  6.9933]],\n",
      "\n",
      "         [[ 8.1213,  8.3309],\n",
      "          [ 8.5405,  8.7500],\n",
      "          [ 8.9596,  9.1692]]]], grad_fn=<ThnnBatchNormBackward>)\n",
      "y_mine:\n",
      "tensor([[[[-0.0314, -0.0097],\n",
      "          [ 0.0119,  0.0336],\n",
      "          [ 0.0552,  0.0768]],\n",
      "\n",
      "         [[ 0.5923,  0.7423],\n",
      "          [ 0.8922,  1.0422],\n",
      "          [ 1.1921,  1.3421]],\n",
      "\n",
      "         [[ 1.7050,  1.8874],\n",
      "          [ 2.0697,  2.2521],\n",
      "          [ 2.4344,  2.6168]],\n",
      "\n",
      "         [[ 3.0913,  3.3009],\n",
      "          [ 3.5105,  3.7201],\n",
      "          [ 3.9297,  4.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4881,  0.5098],\n",
      "          [ 0.5314,  0.5531],\n",
      "          [ 0.5747,  0.5964]],\n",
      "\n",
      "         [[ 4.1912,  4.3412],\n",
      "          [ 4.4912,  4.6411],\n",
      "          [ 4.7911,  4.9410]],\n",
      "\n",
      "         [[ 6.0815,  6.2639],\n",
      "          [ 6.4462,  6.6286],\n",
      "          [ 6.8109,  6.9933]],\n",
      "\n",
      "         [[ 8.1213,  8.3309],\n",
      "          [ 8.5405,  8.7500],\n",
      "          [ 8.9596,  9.1692]]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bn = bn.train()\n",
    "bn(x)\n",
    "print(bn.running_mean)\n",
    "bn = bn.eval()\n",
    "\n",
    "y = bn(x)\n",
    "\n",
    "y_mine = torch.zeros_like(y)\n",
    "for i in range(4):\n",
    "    y_mine[:, i, :, :] = (x[:, i, :, :] - bn.running_mean[i]) / torch.sqrt(bn.running_var[i] + bn.eps) * bn.weight[i] + bn.bias[i]\n",
    "    \n",
    "print('y:', y, sep='\\n')\n",
    "print('y_mine:', y_mine, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
